"""init data model

Revision ID: adec5de82a18
Revises: 243cb163160b
Create Date: 2023-12-23 11:40:03.275757

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = "adec5de82a18"
down_revision: Union[str, None] = "243cb163160b"
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "datasets",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("name", sa.String(), nullable=True),
        sa.Column("userid", sa.String(), nullable=True),
        sa.Column("orgid", sa.String(), nullable=True),
        sa.Column("type", sa.String(), nullable=True),
        sa.Column("chat_type", sa.String(), nullable=True),
        sa.Column("sample_size", sa.Integer(), nullable=True),
        sa.Column("number_of_questions", sa.Integer(), nullable=True),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(op.f("ix_datasets_id"), "datasets", ["id"], unique=False)
    op.create_index(op.f("ix_datasets_name"), "datasets", ["name"], unique=False)
    op.create_table(
        "llm_endpoints",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("name", sa.String(), nullable=True),
        sa.Column("endpoint_url", sa.String(), nullable=True),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(op.f("ix_llm_endpoints_id"), "llm_endpoints", ["id"], unique=False)
    op.create_index(
        op.f("ix_llm_endpoints_name"), "llm_endpoints", ["name"], unique=False
    )
    op.create_table(
        "evaluations",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("dataset_id", sa.Integer(), nullable=True),
        sa.Column("llm_endpoint_id", sa.Integer(), nullable=True),
        sa.Column("ts", sa.DateTime(), nullable=True),
        sa.Column("score", sa.Float(), nullable=True),
        sa.ForeignKeyConstraint(
            ["dataset_id"],
            ["datasets.id"],
        ),
        sa.ForeignKeyConstraint(
            ["llm_endpoint_id"],
            ["llm_endpoints.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(op.f("ix_evaluations_id"), "evaluations", ["id"], unique=False)
    op.create_table(
        "qa_data",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("dataset_id", sa.Integer(), nullable=True),
        sa.Column("llm_endpoint_id", sa.Integer(), nullable=True),
        sa.Column("ts", sa.DateTime(), nullable=True),
        sa.Column("score", sa.Float(), nullable=True),
        sa.ForeignKeyConstraint(
            ["dataset_id"],
            ["datasets.id"],
        ),
        sa.ForeignKeyConstraint(
            ["llm_endpoint_id"],
            ["llm_endpoints.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(op.f("ix_qa_data_id"), "qa_data", ["id"], unique=False)
    op.drop_index("ix_book_id", table_name="book")
    op.drop_table("book")
    op.drop_table("author")
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "author",
        sa.Column(
            "id",
            sa.INTEGER(),
            server_default=sa.text("nextval('author_id_seq'::regclass)"),
            autoincrement=True,
            nullable=False,
        ),
        sa.Column("name", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column("age", sa.INTEGER(), autoincrement=False, nullable=True),
        sa.Column(
            "time_created",
            postgresql.TIMESTAMP(timezone=True),
            server_default=sa.text("now()"),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "time_updated",
            postgresql.TIMESTAMP(timezone=True),
            autoincrement=False,
            nullable=True,
        ),
        sa.PrimaryKeyConstraint("id", name="author_pkey"),
        postgresql_ignore_search_path=False,
    )
    op.create_table(
        "book",
        sa.Column("id", sa.INTEGER(), autoincrement=True, nullable=False),
        sa.Column("title", sa.VARCHAR(), autoincrement=False, nullable=True),
        sa.Column(
            "rating",
            sa.DOUBLE_PRECISION(precision=53),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "time_created",
            postgresql.TIMESTAMP(timezone=True),
            server_default=sa.text("now()"),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "time_updated",
            postgresql.TIMESTAMP(timezone=True),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column("author_id", sa.INTEGER(), autoincrement=False, nullable=True),
        sa.ForeignKeyConstraint(
            ["author_id"], ["author.id"], name="book_author_id_fkey"
        ),
        sa.PrimaryKeyConstraint("id", name="book_pkey"),
    )
    op.create_index("ix_book_id", "book", ["id"], unique=False)
    op.drop_index(op.f("ix_qa_data_id"), table_name="qa_data")
    op.drop_table("qa_data")
    op.drop_index(op.f("ix_evaluations_id"), table_name="evaluations")
    op.drop_table("evaluations")
    op.drop_index(op.f("ix_llm_endpoints_name"), table_name="llm_endpoints")
    op.drop_index(op.f("ix_llm_endpoints_id"), table_name="llm_endpoints")
    op.drop_table("llm_endpoints")
    op.drop_index(op.f("ix_datasets_name"), table_name="datasets")
    op.drop_index(op.f("ix_datasets_id"), table_name="datasets")
    op.drop_table("datasets")
    # ### end Alembic commands ###
